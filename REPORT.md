
# 決定事項（今回の実装に当たり仕様として定めた内容）

## 1. importバッチのルール
- スケジュール機能によって1日に1回実施される。
- バッチ成功は0、失敗は1を返す
- データは全て登録するか全てロールバックするか。
    - 但し、user_data.csvとconsumptionは別とする。


## 2. user_data.csvの運用ルール
- ユーザの登録、削除、更新を行いたい場合、data配下に「user_data.csv」の名称にてファイルを配置する。
- CSVファイルにはユーザID、エリア名、プラン名の3つを揃えて全ユーザ分記載する。
- importバッチ実行時に上記のファイルが存在したら以下の処理を行う。
    - CSVファイル内のユーザデータをUserテーブルに格納する。
    - Userテーブルへの登録：×　 CSVファイル：〇 ＝　新規登録ユーザ
    - Userテーブルへの登録：〇　CSVファイル：×　＝　退会済みユーザ
    - Userテーブルへの登録：〇　CSVファイル：〇　エリア名・プラン名が異なる　＝　更新ユーザ
        - 更新ユーザの場合、新規の内容にて新しくデータを作成する。（従来のデータは削除せず履歴として残す）
- データ登録後、user_data.csvファイルをcompletionに移動する。

## 3. consumption CSVファイルの運用ルール
- 使用量が0khだとしてもCSVファイルに記載する。
- importバッチ実行前にdata/consumption配下に「{ユーザID}.csv」の名称にてファイルを配置する。
- importバッチ実行時に上記のファイルが存在したら以下の処理を行う。
    - CSVファイル内に格納されている消費量データをUserConsumptionHistoryテーブルに格納する。
- データ登録後、data/consumption配下のファイルをcompletionに移動する。

## 4. CSVからのデータ取得及び、集計データの作成にはpandasを利用する

## 5. 集計画面には、以下のグラフと表を表示する
- グラフ：過去の電力消費量を曜日・時間帯ごとに示す。
- 表：ユーザの一覧情報を表示
    - ユーザIDをクリックすることで、詳細画面に遷移できる。

## 6. 詳細画面には、以下を表示する
- ユーザのID、エリア名、プラン名を表示する。
- 該当ユーザの過去の電力消費量を曜日・時間帯ごとに示す。

## 7. 集計画面のグラフ表示用の集計データは24Hキャッシュする

## 8. データ登録時のバリデーション
- ユーザテーブルにIDがないCSVファイルの場合
- エリアテーブルに存在しないエリアが指定されている場合
- 料金プランテーブルに存在しないプランが指定されている場合
- ユーザIDが数値でない場合
- ユーザID、エリア名、プラン名のnot null
- ユーザID、プラン、エリアすべて一致の場合の重複排除
- コンサンプションデータが小数以外
- 時刻のフォーマットがおかしい
- ユーザIDと時刻の重複排除
    - 時刻が完全一致していなければ30分おきでなくても登録できるようにする。


<br><br>

# 検討内容（上記の仕様を固めるために検討・考慮した内容）

## importバッチの処理タイミング
- 質問したところ1日1回を想定されているとのことだった。
    - とすると、CeleryやDjango-crontab、Amazon EventBridgeなどを用いたスケジューリング機能で定期実行するのが効率的である。
        - 実際にどの実装をするかは今回は検討外とする。

## ユーザ情報の扱いについて
- user_data.csvに現ユーザの情報が記載されているが、実際の流れを考えると以下の内容なども想定される。
    - 新規契約をするユーザが発生する。
    - 他社への切り替え（退会）をするユーザが発生する。
    - CSVファイル内にある「area」「tariff」などの情報を変更するユーザが発生する。
        - tariffは料金プランとのことで、特に容易に変更されることが想像できる。
- ユーザ情報の連携方法としては、事業者側で管理しているユーザ情報をCSVファイルで連携されると想像する。
    - 本システムでもユーザのCUD機能を付けるのは2度手間となるため、連携されるCSVファイルからユーザのCUD機能を行える必要がある。
        - Create
            - user_idで一致するデータがDBに格納されていない場合、新規登録する。
        - Update
            - user_idで一致するデータがDBに格納されているが、areaとtariffどちらかの値が異なる場合、更新する。
                - summary画面やdetail画面にて、areaやtariffによる集計を検討する際にただ更新するだけだと、データ不整合が起こる。
                - そのため、更新の場合は過去の契約内容も履歴として残しておく必要がある。
        - Delete
            - DBに存在するuser_idがCSVファイルに存在しない場合は削除する（論理削除）
                - 退会していないが、CSVファイルから漏れている場合もあり得るので、論理削除にしておき復元できるようにする。
                    - 但し、復元機能は今回は実装しない。
- user_data.csvに以下のデータも載せてもらうことが理想ではある（事業者様側の仕様にもよると思うので本システムでは考慮外とした。）
    - ユーザのステータス
    - 契約開始日
    - 契約終了日
- もしくは、user_idを送ったらユーザ情報を返すAPIを実装してもらえると良いが、実現可能性は低そう
    - 事業者側にそういう依頼をできるのか？
    - 個人情報の観点からそこまで取得することが難しい？）
- また、追加、更新、削除するユーザのみCSVファイルに記載頂くのが理想的ではあるが、事業者側の対応によると思うので今回は考慮外とした。


## Consumptionデータの扱いについて
- importバッチが毎日実行される場合、現存するCSVの中身を手動で書き換えるより、新しいCSVファイルを作成する方が運用上現実的であると考える。
    - 既存ファイルの更新は不可とし、データの登録・更新は新規ファイルを連携頂くことで、実施することとする。
        - 運用としては、import.pyの実行前にユーザごとの消費量CSVファイルのダウンロード処理が行われ、data/consumptionに格納されることを想定。（もしくは手動でその配下においてもらう。）
            - 過去の計測値が変わることはほとんど発生しない事象であると予測するため、登録済みの計測日時のデータは再登録及び更新は行わない。
                - テーブルにユーザIｄと計測日時でユニーク制約を付け、データの重複登録を省く。
            - もしデータ不整合が発生した場合はデータパッチ or 使い捨てバッチを作成して流す方針を取る。
                - 頻繁に発生する場合は、再検討する。
- 電力が何も消費されていなくても、0khという実績でCSVファイルに記録されることを想定している。
- importバッチが毎日実行されるのであれば、前日分（00:00:00～23:30:00）の消費量のみがCSVファイルで連携されることが理想ではある。（パフォーマンス的にも内部処理の容易性的にも）
    - 但し、そこは事業者側の仕様によると思うので、今回はCSVファイルで送られるデータは期間の指定ができない想定で進める。


## CSVファイルの運用ルールについて
- まずデータ取り込み時のCSVファイルの扱いについて以下2パターンがあるが、案2を採用。
    1. CSV内のデータを変更して利用する。
        - 上記「Consumptionデータの扱いについて」において、CSVファイル内部のデータ変更は不可、データ変更したい場合は新規ファイルを作成することと定めたため、不採用
        - user_data.csvの扱いも統一する。
    2. 毎回新規ファイルを格納する。
        - 採用
- その上で、importバッチ実施後のファイルの扱いについて以下3パターンを検討し、案3を採用。
    1. なにもしない
        - メリット：
            - 追加処理を加える必要がない。
        - デメリット：
            - 実行時にどのファイルが対象となるのか分からない。
            - フォルダ内にある全ファイルを実行するとパフォーマンスが遅くなる。
    2. データ格納したCSVファイルを削除する。
        - メリット
            - 実行時の対象ファイルが明確になる。
        - デメリット
            - 履歴が残らないため、データ取り込みの検証ができない。
                - 別でCSVを保管しておく機能・仕組みが必要となる。
    3. データ格納したCSVファイルを使用済みフォルダに移動する。
        - メリット
            - 実行時の対象ファイルが明確になる。
            - 取り込んだデータの履歴としても残せる
        - デメリット
            - 永続的に保存するとファイル数が膨大になり容量を圧迫する
                - importバッチが毎日実行されるため、実行時に使用済みフォルダにあるファイルを全て消すことで対応可能になる。
                    - データ取り込み後24Hであれば確認できる。
                    - importバッチの中にcsvファイルの削除処理を加える。
                - ※但し、長期間保存が必要な場合はDBや外部ストレージ(Amazon S3など)への格納を検討する必要もあるので、今回は上記機能は実装しない。


## Summary画面の表示内容について
- 事業者の課題として以下の2つがあるはず。
    1. 電力自由化により、他社への切り替えが行われるリスク。
        - 他社への切り替えを抑制するためにもユーザごとに適正プランの提案が必要か。
            - Summaryとして料金プラン別の軸で切った場合、どのプランが人気なのかなどは分かるが適正プランの提案へは繋がらない。
            - 料金プランごとの想定消費量などがあれば、その値との差異で適正プランを使用できているユーザの多少が測れそう。
                - 想定値との乖離があるプランのユーザを個別で見ていくことでユーザへの適正プランの提案に繋がりそう。
    2. 電力の需給を合わせたい。
        - 電力使用量の把握はできるが、どの軸で切るか。
            - 季節：経年変化が見れないと示唆には繋がらなそう。
                - CSVファイルには2016年の6月～12月分しかないため、適さないと考える。
            - 月次：同上
            - 時間帯：6か月分の平均値を取ることでおおよその値が算出できる。
            ・曜日だとこれまでの6か月間のデータでも示唆が見出せるのではないか。
                - dailyで取り込んだ結果の反映があまり変わらないことがデメリット？

- 理想としては、動的なグラフを創りたい。
    - 期間、エリア、料金プランを選択したらその値に応じた集計結果が算出される。
        - そのために、エリア・料金プランはマスタテーブルを作成しておく。
        - 今回の実装では工数の関係で全ユーザを対象とする。

## 集計データの保持方法
- 以下の3パターンを検討。
- 今後変更が起こる可能性を考慮すると、変更容易性が高い方が良いためキャッシュを採用する。
1. 画面表示時に都度算出
    - メリット
        - リアルタイムにデータを反映できる。
    - デメリット
        - 1日に1回しかデータ更新が行われないので、都度算出するメリットがほぼない。
2. キャッシュを利用
    - メリット：
        - 表示データが変わったっとしても処理を変えるだけで良い。
        - DBの容量を食わない。
    - デメリット：履歴が保持できない。過去のデータを見る機能が追加された場合に新しく実装が必要。
3. データベースに保存
    - メリット：
        - 履歴を取れるため、過去データの参照等が低パフォーマンスで出来る。
    - デメリット：
        - 集計データが変わった時にテーブル定義から変更する必要があるため、柔軟性に乏しい。

- まだ確定ではなく、今後変更が起こる可能性を考慮すると、変更容易性が高い方が良い。
    - とした場合、DBではなくキャッシュで対応する。
        - 全ての算出値だけキャッシュしておく。

## 集計データの算出方法
- 切り方が変わっても対応できるようにしたい。
    - 取得するデータは外部から変数で渡す？
    - 集計データ算出ロジックを別で構える？
        - その場合、summaryに記載するか、importに記載するか？

<br><br>

## 質問事項
### 1回目
1. Q：ユーザデータは1事業者を対象としている認識で相違ないでしょうか。
    - A：はい、相違ございません。
2. Q：area, tariffデータが示す役割を教えて頂きたいです。
    - Q：areaは対象事業者を利用しているユーザの居住地等によってカテゴライズされている認識です。
        - A：areaは電力供給エリアのことです。Challengeの値はa1などになっていますが、実際の弊社プロダクトには 北海道電力エリアなどの値が入っています。
    - Q：tariffは調べたところ「関税・税率」などと出てきたのですが、使われ方が分からなかったです。
        - A：tariffは電力料金プランのことです。
3. Q：パフォーマンスを考慮する際、ユーザ数はcsvファイルの60名を考慮すればよいか。他に指標があればご教示頂きたいです。
    - A：データ上は60人ですが、数万〜数十万人のアクセスに耐えうる設計ですとbetterです。
4. Q：docstringのスタイル含めて、則るべきコーディング規約はございますか。
    - A：docstringのスタイルなど指定はないですが、実際のプロダクトですと下記を使用しています。
        - numpydoc https://numpydoc.readthedocs.io/en/latest/format.html
        - black
        - isort
        - flake8
### 2回目
1. Q：ユーザの詳細情報（ステータス（契約済み、解約）や契約期間など）は別テーブルで保持されている想定で良いでしょうか。
    - A：本チャレンジでは、csvに出力されている項目のみがユーザー情報になりますが、詳細情報が追加連携されることを想定した設計をしていただいても構いません。
2. Q：DBに登録したCSVファイルは削除せずそのまま残しておく方針でしょうか。
    - A：メリットデメリットを鑑みた上で、判断はお任せします。
3. Q：残す場合、CSVファイルの中身が書き換えられる可能性はありますか？
    - A：更新を考慮した設計であればベターです。更新を考慮しない場合は、その場合のcsvの連携ルール等をREPORT.mdに記載できていればよいと思います。
4. Q：次にimport.pyが呼び出された場合に、そのファイルを対象とするか否かで悩んでおります。
    - A：メリットデメリットを鑑みた上で、判断はお任せします。対象外とした場合は、csvの連携ルールに影響があるかと思いますので、REPORT.mdに記載できていればよいと思います。
5. Q：areaとtariffは別テーブルで保持していたりするのでしょうか。
    - A：DBの設計から行なっていただくのが本チャレンジになります。要件に対して最適なテーブル設計を大迫さんの方で考えていただけますと幸いです。
6. Q：a1(恐らく地域名)がareaテーブル（マスタテーブルを想定）に存在しない場合のバリデーションチェックを実装するべきか悩んでおります。
    - A：大迫さんの方で考えられるバリデーションを考慮した実装をお願いします。
7. Q：import.pyはどれくらいの間隔で呼び出される認識でしょうか。
    - A：1日1回のイメージです。