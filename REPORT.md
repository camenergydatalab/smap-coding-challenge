# 報告書

## Import

提供されたデータファイルに稀に重複している時刻のデータが存在している。
これはミスなのか、追加集計なのか、修正なのか、捉え方次第で三つの処理方法を提供している。
現在は重複している時刻の電力量をデフォルトで合算したが、更新か、実行停止か改めて検討すべきです。

また、サンプルデータは 60 契約者しかないが、本番の際もっと時間かかると思います。
PostgreSQL を利用しているなら、 COPY を使って、実行時間を短縮できると思います。

## 集計グラフと DB

残念ですが、 Django ORM には、 Group By などのサポートはほぼ使えないので、 SQLAlchemy
を導入し、 SQL を構築することにした。 データ分析のプロジェクトには、 Django ORM
の機能はほぼ使えません。もちろん、 Django ORM を捨て、 SQLAlchemy を使うのもありが、
Monolithic な Django を使う意味がなくなる。

また、集計する際に非常に遅くなるため、また頻繁に過去のデータの更新は考えにくいので、 30
日のキャッシュを設定した。

## フロントエンド分離

一番重要な集計データの API 化しました。完全分離したければ、簡単に切り離すことはできます。
もし完全分離しようとしたら、そもそも Django を使うかどうか検討すべきです。
Django と Rails には CMS のようなウェブサイトを一番適している、
ほぼ全ての開発の必要な機能を揃えています。逆に、機能が特化したサービスには無駄な部分が多く、
複雑なプロジェクトにも、追加の機能を増やすには、かなりこのプロジェクトのように、
おかしなやり方をせざるを得ない。

## コード品質
コード品質には自信がありますが、本番環境にデプロイすることは論外になります。

面接の課題のため、時間とコミュニケーションの制約で、いろんなところには省略しなくてはならない。
本番環境にデプロイするには、以下の点を解決しなければならない。

- 上にも書いたが、フロントエンド完全分離化と統計に非常に役立つ SQLAlchemy と Web
  アプリ以外ツールを相互操作のため、 Django を継続するか否かも議論すべきと思います。
- Import 高速化のため、 PostgreSQL を使える場合は、 COPY を利用すべきです。
- 集計データのキャッシュ方法、期間など状況に合わせて設定する必要がある。
- 静的ファイルは独立の Domain を使うべきです。
  この小さなプロジェクトにはあまり独立サーバーの必要性ないが、今後必要になるとき、簡単に CDN
  などに切り替えるように準備ができます。
- 集計 API で使った strftime は SQLite 独自のもので、
  他のデータベースがサポートしていないので、本番環境に SQLite を使うことはほぼなく、
  データベースによって書き直す必要がある。
