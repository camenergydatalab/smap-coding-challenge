# 確認観点
## a.アーキテクチャ
### データの処理と保存について
・importコマンド実行時の処理と保存<br>
１、pd.read_csv<br>
２、１をto_pickleでpickle_fileへ<br>
３、２をto_sqlでDBに保存<br>

・存在するファイルの既存の行の値が更新された場合対応できないので、もっと丁寧な処理を書きたい(時間があれば)。<br>
・UserやConsumptionに変更がない場合は、CalculatedConsumptionの作成や更新をしないようにしたい(時間があれば)。<br>
・本番環境で複数人がimportコマンドを走らせた際に、データの整合性が保たれるよう排他制御をしたい(時間があれば)<br>

### バックエンドとフロントエンドの分離
templateを使わなくていいのであれば、DRFでAPIを作成しレスポンスをjson形式にしていたと思う(時間があれば)。

## b.正しさ
・csvデータに重複が発生している際、本来であればエラーにすべきだが、今回は重複している行を削除し処理を成功させる実装にした。

## c.コードの質
・処理が長くなりすぎないように関数への切り出しをした。<br>
・ハードコーディングをさけるため、 `constants.py` を作成した。<br>

## d.テスト
・sql_alchemyを使用したことで起こっていると思われるエラーを解決したかった(時間があれば)

# 技術的な決定事項
・importコマンドの処理速度<br>
初めはbulk_createを使って実装したが、処理に80秒前後かかっていた。<br>
そのため、別の方法で実装したことで処理が17秒前後になった。<br>
ただし、 `コードが増えてしまった` `pickleファイルの管理も必要になる` `そもそも処理速度を重視すべきなのか` という課題があるため、<br>
重視すべき内容について検討し、それに合わせたコードを書くべきだと思った。<br>

・consumptionの合計を出力する処理速度<br>
月ごとの全ユーザーの消費量合計を出力する際、pandasで処理すると5秒ほどかかってしまった。<br>
getのリクエストの度にconsumptionを計算するのは現実的ではないと判断し、
計算されたデータを保持するテーブル `CalculatedConsumption` を作成した。


# 問題点
・`urls.py` のURL指定部分の書き方がDjango2.0より前のバージョンの書き方になっていたため、修正した。

# 仕様について確認すべきだと思ったこと
・importコマンド実行時の処理速度はどのくらいの遅さまで許容されるのか<br>
・timezoneはどの国に設定すべきか<br>
・全てのuserがconsumptionを持つユーザーなのか？admin権限のuser等とconsumptionを持つuserを分けるべきか<br>
